<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>【Auto-Task项目总结】 - 无糖-川大LLM实习Blog</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="无糖-川大LLM实习Blog"><meta name="msapplication-TileImage" content="/img/favicon.svg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="无糖-川大LLM实习Blog"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="项目汇总"><meta property="og:type" content="blog"><meta property="og:title" content="【Auto-Task项目总结】"><meta property="og:url" content="https://llm-frame-group.github.io/2023/06/24/%E3%80%90Auto-Task%E9%A1%B9%E7%9B%AE%E6%80%BB%E7%BB%93%E3%80%91/"><meta property="og:site_name" content="无糖-川大LLM实习Blog"><meta property="og:description" content="项目汇总"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://llm-frame-group.github.io/2023/06/24/%E3%80%90Auto-Task%E9%A1%B9%E7%9B%AE%E6%80%BB%E7%BB%93%E3%80%91/%E5%91%BD%E4%BB%A4%E4%BD%93.png"><meta property="og:image" content="https://llm-frame-group.github.io/2023/06/24/%E3%80%90Auto-Task%E9%A1%B9%E7%9B%AE%E6%80%BB%E7%BB%93%E3%80%91/%E6%B5%81%E7%A8%8B.png"><meta property="og:image" content="https://llm-frame-group.github.io/2023/06/24/%E3%80%90Auto-Task%E9%A1%B9%E7%9B%AE%E6%80%BB%E7%BB%93%E3%80%91/%E8%B0%B7%E6%AD%8C%E6%90%9C%E7%B4%A2%E6%B5%81%E7%A8%8B%E4%B8%8E%E6%A0%BC%E5%BC%8F%E8%AF%B4%E6%98%8E.png"><meta property="og:image" content="https://llm-frame-group.github.io/2023/06/24/%E3%80%90Auto-Task%E9%A1%B9%E7%9B%AE%E6%80%BB%E7%BB%93%E3%80%91/%E7%BD%91%E9%A1%B5%E7%88%AC%E5%8F%96%E6%B5%81%E7%A8%8B.png"><meta property="og:image" content="https://llm-frame-group.github.io/2023/06/24/%E3%80%90Auto-Task%E9%A1%B9%E7%9B%AE%E6%80%BB%E7%BB%93%E3%80%91/%E8%AE%BA%E6%96%87%E4%B8%8B%E8%BD%BD%E6%B5%81%E7%A8%8B.png"><meta property="og:image" content="https://llm-frame-group.github.io/2023/06/24/%E3%80%90Auto-Task%E9%A1%B9%E7%9B%AE%E6%80%BB%E7%BB%93%E3%80%91/%E8%AE%BA%E6%96%87%E6%80%BB%E7%BB%93%E6%B5%81%E7%A8%8B.png"><meta property="og:image" content="https://llm-frame-group.github.io/2023/06/24/%E3%80%90Auto-Task%E9%A1%B9%E7%9B%AE%E6%80%BB%E7%BB%93%E3%80%91/image-20230624105717473.png"><meta property="og:image" content="https://llm-frame-group.github.io/2023/06/24/%E3%80%90Auto-Task%E9%A1%B9%E7%9B%AE%E6%80%BB%E7%BB%93%E3%80%91/image-20230624105746920.png"><meta property="og:image" content="https://llm-frame-group.github.io/2023/06/24/%E3%80%90Auto-Task%E9%A1%B9%E7%9B%AE%E6%80%BB%E7%BB%93%E3%80%91/image-20230624105801989.png"><meta property="og:image" content="https://llm-frame-group.github.io/2023/06/24/%E3%80%90Auto-Task%E9%A1%B9%E7%9B%AE%E6%80%BB%E7%BB%93%E3%80%91/image-20230624105820206.png"><meta property="og:image" content="https://llm-frame-group.github.io/2023/06/24/%E3%80%90Auto-Task%E9%A1%B9%E7%9B%AE%E6%80%BB%E7%BB%93%E3%80%91/image-20230624105845574.png"><meta property="og:image" content="https://llm-frame-group.github.io/2023/06/24/%E3%80%90Auto-Task%E9%A1%B9%E7%9B%AE%E6%80%BB%E7%BB%93%E3%80%91/image-20230624105835562.png"><meta property="og:image" content="https://llm-frame-group.github.io/2023/06/24/%E3%80%90Auto-Task%E9%A1%B9%E7%9B%AE%E6%80%BB%E7%BB%93%E3%80%91/image-20230624105858375.png"><meta property="og:image" content="https://llm-frame-group.github.io/2023/06/24/%E3%80%90Auto-Task%E9%A1%B9%E7%9B%AE%E6%80%BB%E7%BB%93%E3%80%91/image-20230624105914367.png"><meta property="og:image" content="https://llm-frame-group.github.io/2023/06/24/%E3%80%90Auto-Task%E9%A1%B9%E7%9B%AE%E6%80%BB%E7%BB%93%E3%80%91/image-20230624105926143.png"><meta property="og:image" content="https://llm-frame-group.github.io/2023/06/24/%E3%80%90Auto-Task%E9%A1%B9%E7%9B%AE%E6%80%BB%E7%BB%93%E3%80%91/image-20230624105947505.png"><meta property="article:published_time" content="2023-06-24T21:32:49.000Z"><meta property="article:modified_time" content="2023-06-24T14:33:27.390Z"><meta property="article:author" content="momomono6 珠箔飘灯 烧烤团子"><meta property="article:tag" content="auto-task"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="https://llm-frame-group.github.io/2023/06/24/%E3%80%90Auto-Task%E9%A1%B9%E7%9B%AE%E6%80%BB%E7%BB%93%E3%80%91/%E5%91%BD%E4%BB%A4%E4%BD%93.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://llm-frame-group.github.io/2023/06/24/%E3%80%90Auto-Task%E9%A1%B9%E7%9B%AE%E6%80%BB%E7%BB%93%E3%80%91/"},"headline":"【Auto-Task项目总结】","image":["https://llm-frame-group.github.io/2023/06/24/%E3%80%90Auto-Task%E9%A1%B9%E7%9B%AE%E6%80%BB%E7%BB%93%E3%80%91/%E5%91%BD%E4%BB%A4%E4%BD%93.png","https://llm-frame-group.github.io/2023/06/24/%E3%80%90Auto-Task%E9%A1%B9%E7%9B%AE%E6%80%BB%E7%BB%93%E3%80%91/%E6%B5%81%E7%A8%8B.png","https://llm-frame-group.github.io/2023/06/24/%E3%80%90Auto-Task%E9%A1%B9%E7%9B%AE%E6%80%BB%E7%BB%93%E3%80%91/%E8%B0%B7%E6%AD%8C%E6%90%9C%E7%B4%A2%E6%B5%81%E7%A8%8B%E4%B8%8E%E6%A0%BC%E5%BC%8F%E8%AF%B4%E6%98%8E.png","https://llm-frame-group.github.io/2023/06/24/%E3%80%90Auto-Task%E9%A1%B9%E7%9B%AE%E6%80%BB%E7%BB%93%E3%80%91/%E7%BD%91%E9%A1%B5%E7%88%AC%E5%8F%96%E6%B5%81%E7%A8%8B.png","https://llm-frame-group.github.io/2023/06/24/%E3%80%90Auto-Task%E9%A1%B9%E7%9B%AE%E6%80%BB%E7%BB%93%E3%80%91/%E8%AE%BA%E6%96%87%E4%B8%8B%E8%BD%BD%E6%B5%81%E7%A8%8B.png","https://llm-frame-group.github.io/2023/06/24/%E3%80%90Auto-Task%E9%A1%B9%E7%9B%AE%E6%80%BB%E7%BB%93%E3%80%91/%E8%AE%BA%E6%96%87%E6%80%BB%E7%BB%93%E6%B5%81%E7%A8%8B.png","https://llm-frame-group.github.io/2023/06/24/%E3%80%90Auto-Task%E9%A1%B9%E7%9B%AE%E6%80%BB%E7%BB%93%E3%80%91/image-20230624105717473.png","https://llm-frame-group.github.io/2023/06/24/%E3%80%90Auto-Task%E9%A1%B9%E7%9B%AE%E6%80%BB%E7%BB%93%E3%80%91/image-20230624105746920.png","https://llm-frame-group.github.io/2023/06/24/%E3%80%90Auto-Task%E9%A1%B9%E7%9B%AE%E6%80%BB%E7%BB%93%E3%80%91/image-20230624105801989.png","https://llm-frame-group.github.io/2023/06/24/%E3%80%90Auto-Task%E9%A1%B9%E7%9B%AE%E6%80%BB%E7%BB%93%E3%80%91/image-20230624105820206.png","https://llm-frame-group.github.io/2023/06/24/%E3%80%90Auto-Task%E9%A1%B9%E7%9B%AE%E6%80%BB%E7%BB%93%E3%80%91/image-20230624105845574.png","https://llm-frame-group.github.io/2023/06/24/%E3%80%90Auto-Task%E9%A1%B9%E7%9B%AE%E6%80%BB%E7%BB%93%E3%80%91/image-20230624105835562.png","https://llm-frame-group.github.io/2023/06/24/%E3%80%90Auto-Task%E9%A1%B9%E7%9B%AE%E6%80%BB%E7%BB%93%E3%80%91/image-20230624105858375.png","https://llm-frame-group.github.io/2023/06/24/%E3%80%90Auto-Task%E9%A1%B9%E7%9B%AE%E6%80%BB%E7%BB%93%E3%80%91/image-20230624105914367.png","https://llm-frame-group.github.io/2023/06/24/%E3%80%90Auto-Task%E9%A1%B9%E7%9B%AE%E6%80%BB%E7%BB%93%E3%80%91/image-20230624105926143.png","https://llm-frame-group.github.io/2023/06/24/%E3%80%90Auto-Task%E9%A1%B9%E7%9B%AE%E6%80%BB%E7%BB%93%E3%80%91/image-20230624105947505.png"],"datePublished":"2023-06-24T21:32:49.000Z","dateModified":"2023-06-24T14:33:27.390Z","author":{"@type":"Person","name":"momomono6 珠箔飘灯 烧烤团子"},"publisher":{"@type":"Organization","name":"无糖-川大LLM实习Blog","logo":{"@type":"ImageObject","url":"https://llm-frame-group.github.io/img/logo.svg"}},"description":"项目汇总"}</script><link rel="canonical" href="https://llm-frame-group.github.io/2023/06/24/%E3%80%90Auto-Task%E9%A1%B9%E7%9B%AE%E6%80%BB%E7%BB%93%E3%80%91/"><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v6.0.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const id = '#' + CSS.escape(location.hash.substring(1));
          const $tabMenu = document.querySelector(`.tabs a[href="${id}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(id);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.3.0"></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.svg" alt="无糖-川大LLM实习Blog" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/LLM-Frame-Group"><i class="fab fa-github"></i></a><a class="navbar-item is-hidden-tablet catalogue" title="目录" href="javascript:;"><i class="fas fa-list-ul"></i></a><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2023-06-24T21:32:49.000Z" title="6/24/2023, 9:32:49 PM">2023-06-24</time>发表</span><span class="level-item"><time dateTime="2023-06-24T14:33:27.390Z" title="6/24/2023, 2:33:27 PM">2023-06-24</time>更新</span><span class="level-item"> momomono6 珠箔飘灯 烧烤团子 </span><span class="level-item">37 分钟读完 (大约5535个字)</span></div></div><h1 class="title is-3 is-size-4-mobile">【Auto-Task项目总结】</h1><div class="content"><blockquote>
<p><em>笔记作者：陆思宇 方正坤 王昕凯@无糖实习</em><br><em>笔记小编：黄诚@安全学术圈</em></p>
</blockquote>
<h3 id="1、研究介绍"><a href="#1、研究介绍" class="headerlink" title="1、研究介绍"></a>1、研究介绍</h3><p>    Auto-Task 是一个实验性的开源应用程序，展示了 GPT-4 语言模型的能力。该程序由LLM大语言模型驱动，通过连接语言模型的”思考”，自主地实现你设定的任何目标。它展示了 大预言模型在自主决策和执行任务方面的潜力。</p>
<p>    Auto-Task利用大语言模型强大的自然语言处理能力，能够理解和生成自然语言文本。它可以接收用户设定的目标，并通过分析和推理生成一系列步骤，以实现这些目标。无论是撰写文章、解答问题、制定计划，还是执行复杂的任务，Auto-Task 都能通过与用户的对话来理解需求，并提供相应的解决方案。</p>
<p>    Auto-Task的灵活性和适应性使其成为各种场景中的有用工具。它可以用于个人的日常事务管理，例如制定旅行计划、组织日程安排或寻求创意灵感。在安全领域，Auto-Task主要的功能可以协助漏洞发布信息的相关搜集以及相关论文的自动化理解和分析，可以针对使用者的问题给出相对客观的答案。</p>
<p>    Auto-Task 的开源性质使得使用者能够自由探索和扩展其功能。它提供了一种研究和实验的平台，以进一步探索自然语言处理和人工智能领域的可能性。</p>
<p>    总之，Auto-Task 是一个令人印象深刻的应用程序，展示了大语言模型的创新能力。它通过自主连接大语言模型的逻辑推理功能，实现用户设定的目标。为之后安全方向的实践做了一定程度的探索。</p>
<h3 id="2、构建思路"><a href="#2、构建思路" class="headerlink" title="2、构建思路"></a>2、构建思路</h3><ul>
<li><p>prompt模块</p>
<ul>
<li><p>prompt模块是auto-task类项目存在的核心和关键要素，该类型项目的主要功能便是基于大语言模型的理解能力按特定的格式命令宿主操作系统去执行一定的工作和任务，所以prompt的模式和构造条件十分重要。</p>
</li>
<li><p>构造：</p>
<p>常规prompt：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">You are Bob, AI  </span><br><span class="line">Your decisions must always be made independently without seeking user assistance.  </span><br><span class="line">The OS you are running on is: windows</span><br><span class="line"></span><br><span class="line">GOALS:</span><br><span class="line"></span><br><span class="line">1.总结之前的所有内容回答问题并输出在返回格式的&quot;text&quot;中，不执行命令Constraints:  </span><br><span class="line"></span><br><span class="line">1.Exclusively use the commands listed in double quotes e.g. &quot;command name&quot;</span><br><span class="line"></span><br><span class="line">Commands:  </span><br><span class="line"></span><br><span class="line">1.get html info: get html info, args: &quot;url&quot;: &quot;&lt;url&gt;&quot;  </span><br><span class="line"></span><br><span class="line">2.download paper: DOWNLOAD PAPER BY KEYWORD, args: &quot;keyword&quot;: &quot;&lt;keyword&gt;&quot;  </span><br><span class="line"></span><br><span class="line">3.google: Google Search, args: &quot;query&quot;: &quot;&lt;query&gt;&quot;Resources:</span><br><span class="line"></span><br><span class="line">current finished:  </span><br><span class="line"></span><br><span class="line">You should only respond in JSON format as described below  </span><br><span class="line">Response Format:  </span><br><span class="line">&#123;  </span><br><span class="line">    &quot;thoughts&quot;: &#123;  </span><br><span class="line">        &quot;text&quot;: &quot;what you thought,this part can be long&quot;,  </span><br><span class="line">        &quot;plan&quot;: &quot;- short bulleted\n- list that conveys\n- long-term plan&quot;  </span><br><span class="line">    &#125;,  </span><br><span class="line">    &quot;command&quot;: &#123;  </span><br><span class="line">        &quot;name&quot;: &quot;command name&quot;,  </span><br><span class="line">        &quot;args&quot;: &#123;  </span><br><span class="line">            &quot;arg name&quot;: &quot;value&quot;  </span><br><span class="line">        &#125;  </span><br><span class="line">    &#125;  </span><br><span class="line">&#125;  </span><br><span class="line">Ensure the response can be parsed by Python json.loads</span><br></pre></td></tr></table></figure>

<p>我们可以把一个prompt分割为四个部分，说明、限制、命令、返回格式：</p>
<p>1.说明：阐述你需要llm扮演的角色或使用场景</p>
<p>2.限制：限制命令选择及任务限制必须在已有的命令条件下完成</p>
<p>3.命令：可以允许选择的用来解决问题的命令</p>
<p>4.返回格式：包括陈述，计划和命令控制，为json格式。</p>
<p>prompt运行案例：</p>
<p>例如上述的prompt中当你向llm询问怎么得知BBC今日报道时，其返回结果如下所示：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&#123;  </span><br><span class="line">  &quot;thoughts&quot;: &#123;  </span><br><span class="line">    &quot;text&quot;: &quot;Based on the BBC homepage HTML, here are the top news headlines today:&quot;,  </span><br><span class="line">    &quot;plan&quot;: &quot;- Report the top headlines and summaries from [bbc.com](http://bbc.com/) homepage&quot;  </span><br><span class="line">  &#125;,  </span><br><span class="line">  &quot;command&quot;: &#123;  </span><br><span class="line">    &quot;name&quot;: &quot;get html info&quot;,  </span><br><span class="line">    &quot;args&quot;: &#123;  </span><br><span class="line">      &quot;url&quot;: &quot;[https://www.bbc.com/](https://www.bbc.com/)&quot;  </span><br><span class="line">    &#125;  </span><br><span class="line">  &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li><p>可以观察到llm告诉了我们它要获取BBC的报道的plan以及陈述，并返回了命令控制符，name为get html info，网站为<a target="_blank" rel="noopener" href="https://www.bbc.com/news">Home - BBC News</a>，于是操作系统便访问BBC主页分析并总结内容，llm再决定下一步的计划。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">class PromptGenerator:</span><br><span class="line"></span><br><span class="line">    def __init__(self) -&gt; None:</span><br><span class="line"></span><br><span class="line">    self.constraints = [</span><br><span class="line">    Exclusively use the commands listed in double quotes e.g. &quot;command name&quot; </span><br><span class="line">    ]  </span><br><span class="line">    self.commands = []  </span><br><span class="line">    self.resources = []  </span><br><span class="line">    self.performance_evaluation = []  </span><br><span class="line">    self.goals = []  </span><br><span class="line">    self.command_registry = None  </span><br><span class="line">    self.name = &quot;Bob&quot;  </span><br><span class="line">    self.role = &quot;AI&quot;  </span><br><span class="line">    self.response_format = &#123;</span><br><span class="line">    &quot;thoughts&quot;: &#123;  </span><br><span class="line">        &quot;text&quot;: &quot;what you thought,this part can be long&quot;,  </span><br><span class="line">        &quot;plan&quot;: &quot;- short bulleted\n- list that conveys\n- long-term plan&quot;,  </span><br><span class="line">    &#125;,  </span><br><span class="line">    &quot;command&quot;: </span><br><span class="line">    &#123;</span><br><span class="line">    &quot;name&quot;: &quot;command name&quot;, </span><br><span class="line">    &quot;args&quot;: &#123;&quot;arg name&quot;: &quot;value&quot;</span><br><span class="line">    &#125;</span><br><span class="line">    &#125;, </span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>在每一步prompt构造时只需修改该对象中的内容，最后通过读取该对象的内容来生成最新需要的prompt即可。</p>
</li>
<li><p><strong>命令目录及插件管理</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">def command(</span><br><span class="line">name: str,  </span><br><span class="line">description: str,  </span><br><span class="line">signature: str = &quot;&quot;,  </span><br><span class="line">enabled: bool = True,  </span><br><span class="line">disabled_reason: Optional[str] = None,  </span><br><span class="line">) </span><br><span class="line"></span><br><span class="line">def decorator(func: Callable[..., Any]) -&gt; Command:</span><br><span class="line">cmd = Command(  </span><br><span class="line">    name=name,  </span><br><span class="line">    description=description,  </span><br><span class="line">    method=func,  </span><br><span class="line">    signature=signature,  </span><br><span class="line">    enabled=enabled,  </span><br><span class="line">    disabled_reason=disabled_reason,  </span><br><span class="line">)  </span><br><span class="line"></span><br><span class="line">@functools.wraps(func)  </span><br><span class="line">def wrapper(*args, **kwargs) -&gt; Any:  </span><br><span class="line">    return func(*args, **kwargs)  </span><br><span class="line"></span><br><span class="line">wrapper.command = cmd  </span><br><span class="line"></span><br><span class="line">setattr(wrapper, AUTO_GPT_COMMAND_IDENTIFIER, True)  </span><br><span class="line"></span><br><span class="line">return wrapper </span><br><span class="line">return decorator </span><br></pre></td></tr></table></figure>

<h6 id="当有新插件更新到项目时，仅需在插件参考中加入导入插件的python文件，即可自动导入文件中使用了如上装饰函数装饰的函数进可调用命令的目录中。"><a href="#当有新插件更新到项目时，仅需在插件参考中加入导入插件的python文件，即可自动导入文件中使用了如上装饰函数装饰的函数进可调用命令的目录中。" class="headerlink" title="当有新插件更新到项目时，仅需在插件参考中加入导入插件的python文件，即可自动导入文件中使用了如上装饰函数装饰的函数进可调用命令的目录中。"></a>当有新插件更新到项目时，仅需在插件参考中加入导入插件的python文件，即可自动导入文件中使用了如上装饰函数装饰的函数进可调用命令的目录中。</h6></li>
<li><p>命令体构建</p>
<img src="/2023/06/24/%E3%80%90Auto-Task%E9%A1%B9%E7%9B%AE%E6%80%BB%E7%BB%93%E3%80%91/%E5%91%BD%E4%BB%A4%E4%BD%93.png" class="" alt="【Auto-Task项目总结】">
</li>
<li><p>prompt运行逻辑</p>
<img src="/2023/06/24/%E3%80%90Auto-Task%E9%A1%B9%E7%9B%AE%E6%80%BB%E7%BB%93%E3%80%91/%E6%B5%81%E7%A8%8B.png" class="" alt="【Auto-Task项目总结】">

<ul>
<li>本项目目前实现的功能主要为联网查询及论文内容总结，为解决auto-gpt任务分解过盛的问题，我们采用简单的剩余任务分解数绑定任务类型的方式进行分解，举例：初始任务分解数为2，允许自主执行两次任务，llm首先执行搜索引擎的搜索工作，任务分解数+1&#x3D;3，llm分析之后选取某一个网页进行爬取并得到内容总结，任务分解数-1&#x3D;2，随后llm想根据已有知识总结得到答案，任务分解数-1-1&#x3D;0，退出命令执行输出结果；</li>
</ul>
</li>
<li><p>memory模块</p>
<ul>
<li><p>存储功能</p>
<ul>
<li>存储本任务已执行操作的结果，包括论文总结，网页总结，命令执行记录</li>
</ul>
</li>
<li><p>总结调用</p>
<ul>
<li>当需要调用总结命令时，会把这些记录作为参考源提供给llm</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="文本处理（text-processing）模块总结"><a href="#文本处理（text-processing）模块总结" class="headerlink" title="文本处理（text_processing）模块总结"></a>文本处理（text_processing）模块总结</h2><p>summarize_text()函数是text_processing模块中的一个辅助函数，功能为被其他模块的函数调用，接受传入的一段长度任意的文本字符串和指定的问题，并返回由模型基于这一段文本针对这一指定问题进行的总结。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">def summarize_text(text: str, question: str) -&gt; str:</span><br><span class="line">    if not text:</span><br><span class="line">        return &quot;Error: No text to summarize&quot;</span><br><span class="line"></span><br><span class="line">    summaries = []</span><br><span class="line">    chunks = list(</span><br><span class="line">        split_text(text, max_length=3072, question=question),</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    for i, chunk in enumerate(chunks):</span><br><span class="line">        messages = create_message(chunk, question)</span><br><span class="line">        try:</span><br><span class="line">            summary = chat_with_claude(message=messages)</span><br><span class="line">            summaries.append(summary)</span><br><span class="line">            time.sleep(10)</span><br><span class="line">        except Exception as err:</span><br><span class="line">            return f&quot;Error: &#123;err&#125;&quot;</span><br><span class="line"></span><br><span class="line">    combined_summary = &quot;\n&quot;.join(summaries)</span><br><span class="line">    messages = create_message(combined_summary, question)</span><br><span class="line"></span><br><span class="line">    return chat_with_claude(message=messages)</span><br></pre></td></tr></table></figure>

<p>该函数利用split_text()函数将传入的文本分割成长度合适的文本块，然后将其包装成json格式发送给模型进行总结。为了保证最后的总结能够概括传入文本的所有内容，所有分段的总结内容会在最后重新组合在一起发送给模型进行一次总结。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">import spacy</span><br><span class="line">from chat import chat_with_claude</span><br><span class="line"></span><br><span class="line">def split_text(text: str, max_length: int = 3000, question: str = &quot;&quot;,) -&gt; Generator[str, None, None]:</span><br><span class="line">    flattened_paragraphs = &quot; &quot;.join(text.split(&quot;\n&quot;))</span><br><span class="line">    nlp = spacy.load(&quot;en_core_web_sm&quot;)</span><br><span class="line">    nlp.add_pipe(&quot;sentencizer&quot;)</span><br><span class="line">    doc = nlp(flattened_paragraphs)</span><br><span class="line">    sentences = [sent.text.strip() for sent in doc.sents]</span><br><span class="line"></span><br><span class="line">    current_chunk = []</span><br><span class="line"></span><br><span class="line">    for sentence in sentences:</span><br><span class="line">        message_with_additional_sentence = [</span><br><span class="line">            create_message(&quot; &quot;.join(current_chunk) + &quot; &quot; + sentence, question)</span><br><span class="line">        ]</span><br><span class="line"></span><br><span class="line">        expected_length = count_message_length(message_with_additional_sentence)</span><br><span class="line">        if expected_length &lt;= max_length:</span><br><span class="line">            current_chunk.append(sentence)</span><br><span class="line">        else:</span><br><span class="line">            yield &quot; &quot;.join(current_chunk)</span><br><span class="line">            current_chunk = [sentence]</span><br><span class="line">            message_this_sentence_only = [</span><br><span class="line">                create_message(&quot; &quot;.join(current_chunk), question)</span><br><span class="line">            ]</span><br><span class="line">            expected_length = len(message_this_sentence_only) + 1</span><br><span class="line">            if expected_length &gt; max_length:</span><br><span class="line">                raise ValueError(</span><br><span class="line">                    f&quot;Sentence is too long in webpage: &#123;expected_length&#125; tokens.&quot;</span><br><span class="line">                )</span><br><span class="line"></span><br><span class="line">    if current_chunk:</span><br><span class="line">        yield &quot; &quot;.join(current_chunk)</span><br></pre></td></tr></table></figure>

<p>split_text()函数是一个生成器，在调用spacy进行文本分词后依次生成限制长度的文本块返回给summarize_text()函数<br>在auto-GPT项目中，文本长度衡量和分割的方式是调用tiktoken库，将文本块转化为一段token，并以句子为单位计算当前长度的文本token消耗是否溢出。但tiktoken库是由openAI开发的子词标记化工具，在以chat-GPT为交互模型的项目上有很好的表现，但是在其他大语言模型上，由于其token构建方式的可能存在不同，不能保证使用效果；基于词向量化的文本分割功能开发尚未完全，因此当前项目的分段方式为测算字符串长度。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">def create_message(chunk: str, question: str) -&gt; Dict[str, str]:</span><br><span class="line">    return &#123;</span><br><span class="line">        &quot;content&quot;: f&#x27;&quot;&quot;&quot;&#123;chunk&#125;&quot;&quot;&quot; Using the above text, answer the following&#x27;</span><br><span class="line">        f&#x27; question: &quot;&#123;question&#125;&quot; -- if the question cannot be answered using the text,&#x27;</span><br><span class="line">        &quot; summarize the text.&quot;,</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">def count_message_length(messages: list) -&gt; int:</span><br><span class="line">    length = 0</span><br><span class="line">    for message in messages:</span><br><span class="line">        length += len(str(message))</span><br><span class="line">    return length</span><br></pre></td></tr></table></figure>

<p>需要进行总结的文本块会在create_message()函数中被包装成一个json格式的信息，该信息要求模型仅针对给定的文本内容回答问题或总结内容。</p>
<h1 id="插件功能梳理"><a href="#插件功能梳理" class="headerlink" title="插件功能梳理"></a>插件功能梳理</h1><h2 id="插件实现的通用原理"><a href="#插件实现的通用原理" class="headerlink" title="插件实现的通用原理"></a>插件实现的通用原理</h2><h3 id="·-main函数："><a href="#·-main函数：" class="headerlink" title="· main函数："></a>· main函数：</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">command_registry = CommandRegistry()</span><br><span class="line">command_categories = [</span><br><span class="line">    &quot;crawler_selenium&quot;,</span><br><span class="line">    &quot;paper_selenium&quot;,</span><br><span class="line">    &quot;autogpt.commands.google_search&quot;</span><br><span class="line"></span><br><span class="line">]</span><br><span class="line">for command_category in command_categories:</span><br><span class="line">    command_registry.import_commands(command_category)</span><br></pre></td></tr></table></figure>

<p>新建CommandRegisry类并在command_catagories列表下写入待使用的插件名（文件名），由import_commands()函数导入对应插件，以确保相关函数可以在后续过程中被调用。</p>
<h3 id="·-Command模块："><a href="#·-Command模块：" class="headerlink" title="· Command模块："></a>· Command模块：</h3><p>在CommandRegistry类下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">def import_commands(self, module_name: str) -&gt; None:</span><br><span class="line"></span><br><span class="line">    module = importlib.import_module(module_name)</span><br><span class="line"></span><br><span class="line">    for attr_name in dir(module):</span><br><span class="line">        attr = getattr(module, attr_name)</span><br><span class="line">        # Register decorated functions</span><br><span class="line">        if hasattr(attr, AUTO_GPT_COMMAND_IDENTIFIER) and getattr(</span><br><span class="line">            attr, AUTO_GPT_COMMAND_IDENTIFIER</span><br><span class="line">        ):</span><br><span class="line">            self.register(attr.command)</span><br><span class="line">        # Register command classes</span><br><span class="line">        elif (</span><br><span class="line">            inspect.isclass(attr) and issubclass(attr, Command) and attr != Command</span><br><span class="line">        ):</span><br><span class="line">            cmd_instance = attr()</span><br><span class="line">            self.register(cmd_instance)</span><br></pre></td></tr></table></figure>

<p>该函数从导入的模块中的筛选被command装饰器标记的命令插件，并将这些插件注册为Command对象，最终添加到CommandRegistry对象的commands字典中。这样，在后续的操作中，可以通过命令名称从commands字典中获取对应的命令对象，以执行相应的操作。</p>
<h3 id="·-提示工程："><a href="#·-提示工程：" class="headerlink" title="· 提示工程："></a>· 提示工程：</h3><p>在PromptGenerator下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">def __init__(self) -&gt; None:</span><br><span class="line"></span><br><span class="line">    self.constraints = [</span><br><span class="line">        &#x27;只使用双引号中列出的命令。“命令名”&#x27;</span><br><span class="line">    ]</span><br><span class="line">    self.commands = []</span><br><span class="line">    self.command_registry = None</span><br></pre></td></tr></table></figure>

<p>在生成prompt时，要求模型只能使用注册在命令目录当中的命令，从而保证模型返回的任务执行步骤总能被某个插件响应。命令目录一般在主函数中会进行初始化。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">def add_command(</span><br><span class="line">        self,</span><br><span class="line">        command_label: str,</span><br><span class="line">        command_name: str,</span><br><span class="line">        args=None,</span><br><span class="line">        function: Optional[Callable] = None,</span><br><span class="line">) -&gt; None:</span><br><span class="line">    if args is None:</span><br><span class="line">        args = &#123;&#125;</span><br><span class="line"></span><br><span class="line">    command_args = &#123;arg_key: arg_value for arg_key, arg_value in args.items()&#125;</span><br><span class="line"></span><br><span class="line">    command = &#123;</span><br><span class="line">        &quot;label&quot;: command_label,</span><br><span class="line">        &quot;name&quot;: command_name,</span><br><span class="line">        &quot;args&quot;: command_args,</span><br><span class="line">        &quot;function&quot;: function,</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    self.commands.append(command)</span><br></pre></td></tr></table></figure>

<p>该函数将每个命令创建一个包含标签、名称、参数和可调用函数的字典，并将该命令字典添加到命令列表中。</p>
<p>基于以上操作，所有给定的插件均在项目中完成了安装，并在之后的使用过程中根据模型给出的执行需求选择对应的命令执行。</p>
<h2 id="当前实现的插件种类"><a href="#当前实现的插件种类" class="headerlink" title="当前实现的插件种类"></a>当前实现的插件种类</h2><ul>
<li>谷歌搜索：<br> 使用DuckDuckGo引擎搜索关键词，返回一个保存有搜索结果和访问链接的列表</li>
<li>网页爬取和总结：<br> 爬取指定网页的所有前端文字内容，并根据给定的问题让模型进行总结</li>
<li>论文管理：<br> 在paperswithcode上下载指定关键词的论文，并总结内容</li>
</ul>
<h2 id="各插件功能的实现方式"><a href="#各插件功能的实现方式" class="headerlink" title="各插件功能的实现方式"></a>各插件功能的实现方式</h2><h3 id="谷歌搜索"><a href="#谷歌搜索" class="headerlink" title="谷歌搜索"></a>谷歌搜索</h3><p>DuckDuckGo是一种注重隐私保护的搜索引擎，为用户提供匿名化的搜索体验。该引擎在Python下可直接调用函数提交查询请求而无需使用API-Key，因此相较于直接使用谷歌搜索的API具有更好的安全性和项目搭建效率。  将关键词和结果条数提交给duckduckgo_search()后，函数以列表形式返回搜索结果，然后调用safe_google_search()函数将结果转换为如上所示的json标准格式。</p>
<img src="/2023/06/24/%E3%80%90Auto-Task%E9%A1%B9%E7%9B%AE%E6%80%BB%E7%BB%93%E3%80%91/%E8%B0%B7%E6%AD%8C%E6%90%9C%E7%B4%A2%E6%B5%81%E7%A8%8B%E4%B8%8E%E6%A0%BC%E5%BC%8F%E8%AF%B4%E6%98%8E.png" class="" alt="【Auto-Task项目总结】">

<h3 id="网页爬取"><a href="#网页爬取" class="headerlink" title="网页爬取"></a>网页爬取</h3><p> 该功能基于Selenium构建爬虫进行网站爬取。访问指定网站加载完成后执行js脚本获取其所有文本内容，然后将这些内容分割到段，再把分割后的文本发送给模型进行内容总结。</p>
<img src="/2023/06/24/%E3%80%90Auto-Task%E9%A1%B9%E7%9B%AE%E6%80%BB%E7%BB%93%E3%80%91/%E7%BD%91%E9%A1%B5%E7%88%AC%E5%8F%96%E6%B5%81%E7%A8%8B.png" class="" alt="【Auto-Task项目总结】">

<h3 id="论文管理"><a href="#论文管理" class="headerlink" title="论文管理"></a>论文管理</h3><p>PDFMiner是一个可以从PDF文档中提取信息的工具，可以把PDF文件转换成HTML等格式。通过这个库，可以较为轻松地从PDF文件当中获取文本内容，从而进行后续操作。  </p>
<img src="/2023/06/24/%E3%80%90Auto-Task%E9%A1%B9%E7%9B%AE%E6%80%BB%E7%BB%93%E3%80%91/%E8%AE%BA%E6%96%87%E4%B8%8B%E8%BD%BD%E6%B5%81%E7%A8%8B.png" class="" alt="【Auto-Task项目总结】">

<img src="/2023/06/24/%E3%80%90Auto-Task%E9%A1%B9%E7%9B%AE%E6%80%BB%E7%BB%93%E3%80%91/%E8%AE%BA%E6%96%87%E6%80%BB%E7%BB%93%E6%B5%81%E7%A8%8B.png" class="" alt="【Auto-Task项目总结】">

<p>论文管理插件主要包含论文批量下载和批量阅读两个功能。<br>下载：当指定关键词后，该插件被调用，在paperswithcode上搜索关键词，然后依次访问并下载前数篇论文到本地指定路径。<br>阅读：从指定路径读取论文，调用PDFMiner对其进行解析，提取文本内容到content字符串中并保存为txt文件（可选），同时将内容发送给模型使其提取摘要。</p>
<h4 id="开源的ChatGPT应用项目查阅和对比"><a href="#开源的ChatGPT应用项目查阅和对比" class="headerlink" title="开源的ChatGPT应用项目查阅和对比"></a>开源的ChatGPT应用项目查阅和对比</h4><p>本方面我们查阅了大量的开源项目，对其源码进行分析阅读，总结了三个较为突出的开源项目并进行对比：</p>
<p>① <strong>ChuanhuChatGPT</strong></p>
<p>​ 川虎为ChatGPT等多种LLM提供了一个轻快好用的Web图形界面和众多附加功能，其旨在为多个大语言模型提供连接接口和自由切换，使得用户可以方便的使用自己部署的大语言模型或者是GPT等模型的 api。在已经开源的项目中，川虎已经部署了主流的GPT的多个版本的模型接口以及其他部分大语言模型接口比如Moss，只要提供相应的api就可以和相应的的模型对话。</p>
<img src="/2023/06/24/%E3%80%90Auto-Task%E9%A1%B9%E7%9B%AE%E6%80%BB%E7%BB%93%E3%80%91/image-20230624105717473.png" class="" alt="【Auto-Task项目总结】">

<p>​ 同时，川虎GPT为大语言模型提供了多种补充功能和潜力挖掘，比如可以上传文件，用自带的prompt模板帮助用户获取更准确的答案，可以保存重要的对话并导出保存等等。此外，该系统还提供了用户的个性化服务，便捷用户的使用。</p>
<p>以下是一些该项目的使用技巧：</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">使用System Prompt可以很有效地设定前提条件。</span><br><span class="line">使用Prompt模板功能时，选择Prompt模板集合文件，然后从下拉菜单中选择想要的prompt。</span><br><span class="line">如果回答不满意，可以使用 重新生成按钮再试一次</span><br><span class="line">输入框支持换行，按 shift enter即可。</span><br><span class="line">可以在输入框按上下箭头在输入历史之间切换</span><br><span class="line">部署到服务器：在 config.json 中设置 <span class="attr">&quot;server_name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;0.0.0.0&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;server_port&quot;</span><span class="punctuation">:</span> &lt;你的端口号&gt;<span class="punctuation">,</span>。</span><br><span class="line">获取公共链接：在 config.json 中设置 <span class="attr">&quot;share&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span>。注意程序必须在运行，才能通过公共链接访问。</span><br><span class="line">在Hugging Face上使用：建议在右上角 复制Space 再使用，这样App反应可能会快一点。</span><br></pre></td></tr></table></figure>

<p>​ 川虎系统的代码逻辑清晰，功能齐全，文件功能分工明确，易读易懂，二次开发的价值和潜力很大。但是正因为代码衔接紧密，因此想要单独剥离功能块的难度较高。川虎GPT本身是一个大语言模型功能的集成，在面向大语言模型应用领域还有很大的挖掘潜力。</p>
<p>② <strong>Hoppin</strong></p>
<p>​ Hoppin为gitee网站上一名作者开源的基于 Java 语言的连接 ChatGPT 的 api 的项目。作者做了一个类GPT的对话聊天系统，同时为用户配置了较为详尽的 api 策略和费用统计。本项目的特点在于作者制作了较为美观的前端，并附加了图片上传和图片生成功能，并为用户提供了较为齐全的身份验证机制和 ChatGPT 的 api 管理策略。以下是一些项目图片。</p>
<img src="/2023/06/24/%E3%80%90Auto-Task%E9%A1%B9%E7%9B%AE%E6%80%BB%E7%BB%93%E3%80%91/image-20230624105746920.png" class="" alt="【Auto-Task项目总结】">

<p>​ 上图是项目的主界面，可以看到基本的聊天功能该项目都具备。</p>
<img src="/2023/06/24/%E3%80%90Auto-Task%E9%A1%B9%E7%9B%AE%E6%80%BB%E7%BB%93%E3%80%91/image-20230624105801989.png" class="" alt="【Auto-Task项目总结】">

<p>​ 上图是为用户设置的 api 管理功能。</p>
<p>​ 本项目的前端界面美观，并且功能相对较全，有利于二次开发和进一步的功能拓展。但比较遗憾的是，项目源码的逻辑设计和代码架构并不清晰，有些许混乱，初次接触源码的开发者可能需要一定的时间来梳理代码逻辑，这可能会是一个小小的缺憾。</p>
<p>③ <strong>chatai-vue</strong></p>
<p>​ chatai-vue项目是使用 vue 高仿了 chatgpt 的前端，后端使用 python flask openai 实现。 后续作者又进行了 openai 的 api 更新，开放了最新的 gpt-3.5-turbo 模型，后端使用了最新模型在分支 toGpt3.5 上，加上了流式响应。 新模型更加强大，更加智能。本项目是完全类仿 ChatGPT 的界面制作的，意图使得拥有 api 的用户可以随时随地较为方便的使用ChatGPT的服务。以下是一些项目图展示。</p>
<img src="/2023/06/24/%E3%80%90Auto-Task%E9%A1%B9%E7%9B%AE%E6%80%BB%E7%BB%93%E3%80%91/image-20230624105820206.png" class="" alt="【Auto-Task项目总结】">

<p>​ 阅读本项目的源码后，觉得代码的逻辑结构清晰，功能设计条理，有很大的二次开发价值，因而，我们后续的项目便基于 chatai-vue 项目进行进一步的研发。</p>
<h4 id="Auto-task前后端服务搭建"><a href="#Auto-task前后端服务搭建" class="headerlink" title="Auto-task前后端服务搭建"></a>Auto-task前后端服务搭建</h4><p>​ 本任务是前端框架和后端服务器的搭建，前端框架中使用 vue 高仿了一个类似 ChatGPT 的前端，服务器端的代码主要使用 Node.js和Express框架实现。</p>
<p>​ Vue.js（或简称为Vue）是一个用于创建用户界面的开源JavaScript框架，也是一个创建单页应用的Web应用框架。Vue所关注的核心是<strong>MVC模式</strong>中的<strong>视图层</strong>，同时，它也能方便地获取数据更新，并通过组件内部特定的方法实现视图与模型的交互。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">MVC全名是Model View Controller，是模型(model)－视图(view)－控制器(controller)的缩写，一种软件设计典范，用一种业务逻辑、数据、界面显示分离的方法组织代码，将业务逻辑聚集到一个部件里面，在改进和个性化定制界面及用户交互的同时，不需要重新编写业务逻辑。MVC被独特的发展起来用于映射传统的输入、处理和输出功能在一个逻辑的图形化用户界面的结构中。</span><br></pre></td></tr></table></figure>

<p><strong>项目部署</strong>：</p>
<p>vue 前端：</p>
<p>下载依赖：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm i</span><br></pre></td></tr></table></figure>

<p>项目运行：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm run dev</span><br></pre></td></tr></table></figure>

<img src="/2023/06/24/%E3%80%90Auto-Task%E9%A1%B9%E7%9B%AE%E6%80%BB%E7%BB%93%E3%80%91/image-20230624105845574.png" class="" alt="【Auto-Task项目总结】">

<p>服务器sever.js文件，直接运行：</p>
<img src="/2023/06/24/%E3%80%90Auto-Task%E9%A1%B9%E7%9B%AE%E6%80%BB%E7%BB%93%E3%80%91/image-20230624105835562.png" class="" alt="【Auto-Task项目总结】">

<p><strong>项目结构</strong>：</p>
<img src="/2023/06/24/%E3%80%90Auto-Task%E9%A1%B9%E7%9B%AE%E6%80%BB%E7%BB%93%E3%80%91/image-20230624105858375.png" class="" alt="【Auto-Task项目总结】">

<p>​ 就具体的业务逻辑，我们对每个新会话进行标注 cid ，并对会话中的每一次问答进行编号标注 idx ，并设定一些规则，例如<code>[DONE]</code>为服务器端回复内容的结束标志等等来方便后续的开发。</p>
<p><strong>项目展示：</strong></p>
<img src="/2023/06/24/%E3%80%90Auto-Task%E9%A1%B9%E7%9B%AE%E6%80%BB%E7%BB%93%E3%80%91/image-20230624105914367.png" class="" alt="【Auto-Task项目总结】">

<img src="/2023/06/24/%E3%80%90Auto-Task%E9%A1%B9%E7%9B%AE%E6%80%BB%E7%BB%93%E3%80%91/image-20230624105926143.png" class="" alt="【Auto-Task项目总结】">

<img src="/2023/06/24/%E3%80%90Auto-Task%E9%A1%B9%E7%9B%AE%E6%80%BB%E7%BB%93%E3%80%91/image-20230624105947505.png" class="" alt="【Auto-Task项目总结】">

<h3 id="3、团队思考"><a href="#3、团队思考" class="headerlink" title="3、团队思考"></a>3、团队思考</h3><p>    本项目团队由三位成员组成，我们致力于团队合作，并积极尝试了大语言模型在安全领域的探索应用。auto-task是以大语言模型为驱动的自动化任务处理工程，对于使用者的需求生成相应的propmt方案交由大语言模型理解并根据模型返回信息执行命令并决定之后的任务方案，团队在网页关键信息搜集，论文下载及总结，搜索引擎信息检索等方面作出了一定的努力，团队认为大语言模型的代码分析能力以及逻辑推理能力在安全领域具有十分广泛的应用价值，值得进一步的深入和研究。</p>
</div><div class="article-licensing box"><div class="licensing-title"><p>【Auto-Task项目总结】</p><p><a href="https://llm-frame-group.github.io/2023/06/24/【Auto-Task项目总结】/">https://llm-frame-group.github.io/2023/06/24/【Auto-Task项目总结】/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>作者</h6><p>momomono6 珠箔飘灯 烧烤团子</p></div></div><div class="level-item is-narrow"><div><h6>发布于</h6><p>2023-06-24</p></div></div><div class="level-item is-narrow"><div><h6>更新于</h6><p>2023-06-24</p></div></div><div class="level-item is-narrow"><div><h6>许可协议</h6><p><a class="icons" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="icon fab fa-creative-commons"></i></a><a class="icons" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="icon fab fa-creative-commons-by"></i></a><a class="icons" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="icon fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/auto-task/">auto-task</a></div><!--!--></article></div><!--!--><nav class="post-navigation mt-4 level is-mobile"><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2023/06/20/%E3%80%90%E8%AE%BA%E6%96%87%E5%AF%BC%E8%AF%BB%E3%80%91The-RefinedWeb-Dataset-for-Falcon-LLM/"><span class="level-item">【论文导读】The RefinedWeb Dataset for Falcon LLM</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><!--!--></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="/img/avatar.png" alt="无糖-SCU LLM框架组"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">无糖-SCU LLM框架组</p><p class="is-size-6 is-block">更新中 ♪（＾∀＾●）ﾉｼ （●´∀｀）♪</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>中国 成都</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">文章</p><a href="/archives"><p class="title">11</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">分类</p><a href="/categories"><p class="title">0</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">标签</p><a href="/tags"><p class="title">3</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/LLM-Frame-Group" target="_blank" rel="noopener">关注我</a></div></div></div><!--!--><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">最新文章</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-06-24T21:32:49.000Z">2023-06-24</time></p><p class="title"><a href="/2023/06/24/%E3%80%90Auto-Task%E9%A1%B9%E7%9B%AE%E6%80%BB%E7%BB%93%E3%80%91/">【Auto-Task项目总结】</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-06-20T10:20:33.000Z">2023-06-20</time></p><p class="title"><a href="/2023/06/20/%E3%80%90%E8%AE%BA%E6%96%87%E5%AF%BC%E8%AF%BB%E3%80%91The-RefinedWeb-Dataset-for-Falcon-LLM/">【论文导读】The RefinedWeb Dataset for Falcon LLM</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-06-20T10:09:21.000Z">2023-06-20</time></p><p class="title"><a href="/2023/06/20/%E3%80%90%E8%AE%BA%E6%96%87%E5%AF%BC%E8%AF%BB%E3%80%91QLoRA%EF%BC%9AEfficient-Finetuning-of-Quantized-LLMs/">【论文导读】QLoRA：Efficient Finetuning of Quantized LLMs</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-06-20T09:50:44.000Z">2023-06-20</time></p><p class="title"><a href="/2023/06/20/%E3%80%90%E8%AE%BA%E6%96%87%E5%AF%BC%E8%AF%BB%E3%80%91Large-language-models-are-human-level-prompt-engineers/">【论文导读】Large language models are human-level prompt engineers</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-06-20T09:40:26.000Z">2023-06-20</time></p><p class="title"><a href="/2023/06/20/%E3%80%90%E8%AE%BA%E6%96%87%E5%AF%BC%E8%AF%BB%E3%80%91ReAct%EF%BC%9ASynergizing-Reasoning-and-Acting-in-Language-Models/">【论文导读】ReAct：Synergizing Reasoning and Acting in Language Models</a></p></div></article></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">归档</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2023/"><span class="level-start"><span class="level-item">2023</span></span><span class="level-end"><span class="level-item tag">11</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">标签</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/Prompt-Engineering/"><span class="tag">Prompt Engineering</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/auto-task/"><span class="tag">auto-task</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"><span class="tag">论文阅读</span><span class="tag">10</span></a></div></div></div></div></div><div class="column-right-shadow is-hidden-widescreen"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3"><div class="card widget" id="toc" data-type="toc"><div class="card-content"><div class="menu"><h3 class="menu-label">目录</h3><ul class="menu-list"><ul class="menu-list"><ul class="menu-list"><li><a class="level is-mobile" href="#1、研究介绍"><span class="level-left"><span class="level-item">1.1.1</span><span class="level-item">1、研究介绍</span></span></a></li><li><a class="level is-mobile" href="#2、构建思路"><span class="level-left"><span class="level-item">1.1.2</span><span class="level-item">2、构建思路</span></span></a></li></ul><li><a class="level is-mobile" href="#文本处理（text-processing）模块总结"><span class="level-left"><span class="level-item">1.2</span><span class="level-item">文本处理（text_processing）模块总结</span></span></a></li></ul><li><a class="level is-mobile" href="#插件功能梳理"><span class="level-left"><span class="level-item">2</span><span class="level-item">插件功能梳理</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#插件实现的通用原理"><span class="level-left"><span class="level-item">2.1</span><span class="level-item">插件实现的通用原理</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#·-main函数："><span class="level-left"><span class="level-item">2.1.1</span><span class="level-item">· main函数：</span></span></a></li><li><a class="level is-mobile" href="#·-Command模块："><span class="level-left"><span class="level-item">2.1.2</span><span class="level-item">· Command模块：</span></span></a></li><li><a class="level is-mobile" href="#·-提示工程："><span class="level-left"><span class="level-item">2.1.3</span><span class="level-item">· 提示工程：</span></span></a></li></ul></li><li><a class="level is-mobile" href="#当前实现的插件种类"><span class="level-left"><span class="level-item">2.2</span><span class="level-item">当前实现的插件种类</span></span></a></li><li><a class="level is-mobile" href="#各插件功能的实现方式"><span class="level-left"><span class="level-item">2.3</span><span class="level-item">各插件功能的实现方式</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#谷歌搜索"><span class="level-left"><span class="level-item">2.3.1</span><span class="level-item">谷歌搜索</span></span></a></li><li><a class="level is-mobile" href="#网页爬取"><span class="level-left"><span class="level-item">2.3.2</span><span class="level-item">网页爬取</span></span></a></li><li><a class="level is-mobile" href="#论文管理"><span class="level-left"><span class="level-item">2.3.3</span><span class="level-item">论文管理</span></span></a></li><li><a class="level is-mobile" href="#3、团队思考"><span class="level-left"><span class="level-item">2.3.4</span><span class="level-item">3、团队思考</span></span></a></li></ul></li></ul></li></ul></div></div><script src="/js/toc.js" defer></script></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.svg" alt="无糖-川大LLM实习Blog" height="28"></a><p class="is-size-7"><span>&copy; 2023 momomono6 珠箔飘灯 烧烤团子</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p><p class="is-size-7">© 2023</p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("zh-cn");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.9/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"想要查找什么...","untitled":"(无标题)","posts":"文章","pages":"页面","categories":"分类","tags":"标签"});
        });</script></body></html>